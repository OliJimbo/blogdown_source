---
title: Responsible Conference Poster Press Releases
author: ~
date: '2018-05-02'
slug: press-releases-rmd
categories: []
tags: []
---
I wanted to leave a quick note on my experience of the press and academic posters at conferences.

I have seen that a few posters have received some media attention this week.

In the only entry that I had a close look at, the analysis was very tenuous and the headline conclusion seemed to rely on the absence of a significant effect (i.e. denial of the antecedent fallacy).

There were other statistical and methodological issues which (I hope) would have picked up were the study peer reviewed.

As trainee researchers we are still learning the ropes.  That is not to say that our work is poor and we should not be trusted, only that we should not be trusted more than more (or less) than experienced academics.  If societies are going to send results from poster (or oral) presentations, there should be safeguards in place to ensure the quality of the studies is adequate prior to sending out press releasese.

That is not to say that posters should always have to be based on peer reviewed papers!  Posters could be seen as a sort of pre-print in which advice is given and discussions take place to improve or test the conclusions of the study.  But sending unfinished and unvetted studies in press packs can lead to unusual circumstances.

I'll give an example from my own experience.

When I was a Masters student I submitted my undergraduate dissertation to the BPS Annual Conference in Dublin (2008).

The study was an experiment into the effect of road side advertising on attention to relevant information.

My relevant stimuli were roadsigns that required a driver to slow down and the distracter stimuli were billboards taken from Google images.  They appeared around the periphery of my laptop screen whilst participants used a secondhand videogame steeringwheel that I got from Gamestation for about £10 steering-wheel to control a crosshair and foot-pedals to respond to the road signs.

I was very flexible with my definition of a laboratory. I took the laptop and steering wheel to peoples houses, different university lab rooms - and I have a very vague memory of collecting data from one participant in a pub. I may just have met them there, I do not remember!

I no longer have the data anymore (pre-dropbox and osf), or the software (no Github) and I even think the dissertation itself has disappeared!

The abstract was accepted and I was asked if I would like to submit it to the press pack.  Me being a naive 23 year old who was coming to the end of his Masters course jumped at the opportunity and the day before the embargo I started receiving phone-calls from various tabloids like the Sun and the Daily Mail asking me about the potential dangers of roadside adverts!

This kind of spiralled out of control and I ended up giving interviews on my lunch break at my shop job to BBC Radio, and was also on 'The Last Word' (Irelands' premier drive time radio station - which was kind of ironic).

I was asked a series of leading questions about the implications of the findings w/r/t life and death e.g. one interviewer said in response to my crude calculations of the impact on stopping times "So we're talking lives here".

It was an excellent experience and I was approached by a number of academics in the area who wanted copies of the dissertation and was even asked if I wanted to apply for a PhD with one!

I didn't include effect sizes, my collection methods were sloppy, but I 'found' an interesting effect that could be made relevant to the public.

Yes - there may be impactful student projects (in the sense that the media can use them to spin a story that the public will enjoy!), but should  *any* significant result on a vaguely topical study be the subject of media exposure?

Shortly after submitting my dissertation in 2007 I asked my supervisor a whether we could prepare it for publication.  They were not enthusiastic, despite it getting a fairly good grade.

It wasn't of good enough quality for an academic journal, and wasn't even remotely peer reviewed.  It was selected based on it's perceived impact, what we would call *click bait* these days at a time when driver distraction was a hot topic and the negative use of mobile phones whilst driving was still being debated.

I know that most student projects that are submitted to the BPS will be of a far better quality than mine, and they will not have made the weird choices I made for data collection.  But at the time we need to ensure that only thorough and credible results are disseminated to the public.

 I was offered a media training session at a reduced rate of £110 which I couldn't afford at the time and was not equipped for dealing with the press.  As such I was happy to go along with whatever I was asked without really thinking about the consequences.

Whether this study had any influence on the field I do not know (I can't find reference to it on google which is a good sign). I do know that the PhD offer didn't go anywhere and the people who read my dissertation didn't get back to me for more information - so the silence was probably louder than any words!

It is only now that I have heard some of the objections from people on twitter (thanks @orbenAmy and @McAleerP), and now that I have a better understanding of open practices and disclosure that I am more critical of the experience.

I don't know about solutions to this. 

Some think that conferences should not send out press releases at all. This would be ideal. Press coverage should be saved for peer reviewed studies, but this is unlikely since it gives publicity to the organisation.

But I think as a bare minimum there should be safeguards in place so that the potential misuse of student work is minimalised.

This could be achieved by requiring that the full papers are reviewed by the selection committee before being included in press-packs.

This would reduce the number of studies released to the press but would also raise the standard of the outputs from conferences.
